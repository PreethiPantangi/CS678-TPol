{'eval_loss': 2.2628049850463867, 'eval_runtime': 0.3322, 'eval_samples_per_second': 180.598, 'eval_steps_per_second': 45.15, 'epoch': 1.0}
{'eval_loss': 0.297101765871048, 'eval_runtime': 0.3319, 'eval_samples_per_second': 180.758, 'eval_steps_per_second': 45.19, 'epoch': 2.0}
{'eval_loss': 0.2717018127441406, 'eval_runtime': 0.3327, 'eval_samples_per_second': 180.352, 'eval_steps_per_second': 45.088, 'epoch': 3.0}
{'loss': 1.5458, 'learning_rate': 8.765432098765432e-06, 'epoch': 3.7}
{'eval_loss': 0.10547663271427155, 'eval_runtime': 0.3307, 'eval_samples_per_second': 181.408, 'eval_steps_per_second': 45.352, 'epoch': 4.0}
{'eval_loss': 0.12184035778045654, 'eval_runtime': 0.3335, 'eval_samples_per_second': 179.908, 'eval_steps_per_second': 44.977, 'epoch': 5.0}
{'eval_loss': 0.1357584297657013, 'eval_runtime': 0.3326, 'eval_samples_per_second': 180.39, 'eval_steps_per_second': 45.097, 'epoch': 6.0}
{'eval_loss': 0.13622020184993744, 'eval_runtime': 0.332, 'eval_samples_per_second': 180.741, 'eval_steps_per_second': 45.185, 'epoch': 7.0}
{'loss': 0.0379, 'learning_rate': 7.530864197530865e-06, 'epoch': 7.41}
{'eval_loss': 0.1054249256849289, 'eval_runtime': 0.3328, 'eval_samples_per_second': 180.268, 'eval_steps_per_second': 45.067, 'epoch': 8.0}
{'eval_loss': 0.13400045037269592, 'eval_runtime': 0.333, 'eval_samples_per_second': 180.163, 'eval_steps_per_second': 45.041, 'epoch': 9.0}
{'eval_loss': 0.13358208537101746, 'eval_runtime': 0.3318, 'eval_samples_per_second': 180.844, 'eval_steps_per_second': 45.211, 'epoch': 10.0}
{'eval_loss': 0.13359424471855164, 'eval_runtime': 0.3335, 'eval_samples_per_second': 179.921, 'eval_steps_per_second': 44.98, 'epoch': 11.0}
{'loss': 0.0105, 'learning_rate': 6.296296296296297e-06, 'epoch': 11.11}
{'eval_loss': 0.12685362994670868, 'eval_runtime': 0.3341, 'eval_samples_per_second': 179.602, 'eval_steps_per_second': 44.9, 'epoch': 12.0}
{'eval_loss': 0.12086694687604904, 'eval_runtime': 0.3335, 'eval_samples_per_second': 179.896, 'eval_steps_per_second': 44.974, 'epoch': 13.0}
{'eval_loss': 0.11690644919872284, 'eval_runtime': 0.3317, 'eval_samples_per_second': 180.873, 'eval_steps_per_second': 45.218, 'epoch': 14.0}
{'loss': 0.0069, 'learning_rate': 5.061728395061729e-06, 'epoch': 14.81}
{'eval_loss': 0.15293653309345245, 'eval_runtime': 0.3319, 'eval_samples_per_second': 180.772, 'eval_steps_per_second': 45.193, 'epoch': 15.0}
{'eval_loss': 0.13697202503681183, 'eval_runtime': 0.3342, 'eval_samples_per_second': 179.532, 'eval_steps_per_second': 44.883, 'epoch': 16.0}
{'eval_loss': 0.14810016751289368, 'eval_runtime': 0.3347, 'eval_samples_per_second': 179.283, 'eval_steps_per_second': 44.821, 'epoch': 17.0}
{'eval_loss': 0.1522979736328125, 'eval_runtime': 0.333, 'eval_samples_per_second': 180.171, 'eval_steps_per_second': 45.043, 'epoch': 18.0}
{'loss': 0.002, 'learning_rate': 3.827160493827161e-06, 'epoch': 18.52}
{'eval_loss': 0.14940032362937927, 'eval_runtime': 0.3331, 'eval_samples_per_second': 180.137, 'eval_steps_per_second': 45.034, 'epoch': 19.0}
{'eval_loss': 0.1479843258857727, 'eval_runtime': 0.3355, 'eval_samples_per_second': 178.847, 'eval_steps_per_second': 44.712, 'epoch': 20.0}
{'eval_loss': 0.14271685481071472, 'eval_runtime': 0.3328, 'eval_samples_per_second': 180.28, 'eval_steps_per_second': 45.07, 'epoch': 21.0}
{'eval_loss': 0.14423586428165436, 'eval_runtime': 0.3308, 'eval_samples_per_second': 181.402, 'eval_steps_per_second': 45.35, 'epoch': 22.0}
{'loss': 0.0017, 'learning_rate': 2.5925925925925925e-06, 'epoch': 22.22}
{'eval_loss': 0.14312317967414856, 'eval_runtime': 0.3328, 'eval_samples_per_second': 180.29, 'eval_steps_per_second': 45.072, 'epoch': 23.0}
{'eval_loss': 0.13777826726436615, 'eval_runtime': 0.3298, 'eval_samples_per_second': 181.953, 'eval_steps_per_second': 45.488, 'epoch': 24.0}
{'eval_loss': 0.13846489787101746, 'eval_runtime': 0.3318, 'eval_samples_per_second': 180.836, 'eval_steps_per_second': 45.209, 'epoch': 25.0}
{'loss': 0.0005, 'learning_rate': 1.3580246913580248e-06, 'epoch': 25.93}
{'eval_loss': 0.13921333849430084, 'eval_runtime': 0.3333, 'eval_samples_per_second': 180.012, 'eval_steps_per_second': 45.003, 'epoch': 26.0}
{'eval_loss': 0.14100241661071777, 'eval_runtime': 0.3316, 'eval_samples_per_second': 180.929, 'eval_steps_per_second': 45.232, 'epoch': 27.0}
{'eval_loss': 0.14102517068386078, 'eval_runtime': 0.3345, 'eval_samples_per_second': 179.384, 'eval_steps_per_second': 44.846, 'epoch': 28.0}
{'eval_loss': 0.14124630391597748, 'eval_runtime': 0.3345, 'eval_samples_per_second': 179.347, 'eval_steps_per_second': 44.837, 'epoch': 29.0}
{'loss': 0.0003, 'learning_rate': 1.234567901234568e-07, 'epoch': 29.63}
{'eval_loss': 0.14039334654808044, 'eval_runtime': 0.3315, 'eval_samples_per_second': 181.003, 'eval_steps_per_second': 45.251, 'epoch': 30.0}
{'train_runtime': 992.5832, 'train_samples_per_second': 16.321, 'train_steps_per_second': 4.08, 'train_loss': 0.19824159647809503, 'epoch': 30.0}
EXACT-MATCH ACCURACY
ACC: 32.86%
MN: 37.04%
NMN: 27.12%
NO. CORRECT TOKENS
ACC: 57.27%
MN: 60.65%
NMN: 52.45%
MAX CORRECT SPAN
ACC: 65.63%
MN: 69.12%
NMN: 60.66%
  3%|███▊                                                                                                                | 135/4050 [00:32<14:57,  4.36it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
  7%|███████▋                                                                                                            | 270/4050 [01:03<14:25,  4.37it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 10%|███████████▌                                                                                                        | 405/4050 [01:34<13:49,  4.39it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 12%|██████████████▎                                                                                                     | 500/4050 [01:57<24:56,  2.37it/s]Saving model checkpoint to models/checkpoint-500
Configuration saved in models/checkpoint-500/config.json
Model weights saved in models/checkpoint-500/pytorch_model.bin
tokenizer config file saved in models/checkpoint-500/tokenizer_config.json
Special tokens file saved in models/checkpoint-500/special_tokens_map.json
 13%|███████████████▍                                                                                                    | 540/4050 [02:16<13:12,  4.43it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 17%|███████████████████▎                                                                                                | 675/4050 [02:46<12:45,  4.41it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 20%|███████████████████████▏                                                                                            | 810/4050 [03:16<12:03,  4.48it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 23%|███████████████████████████                                                                                         | 945/4050 [03:47<11:12,  4.62it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 25%|████████████████████████████▍                                                                                      | 1000/4050 [04:00<21:10,  2.40it/s]Saving model checkpoint to models/checkpoint-1000
Configuration saved in models/checkpoint-1000/config.json
Model weights saved in models/checkpoint-1000/pytorch_model.bin
tokenizer config file saved in models/checkpoint-1000/tokenizer_config.json
Special tokens file saved in models/checkpoint-1000/special_tokens_map.json
 27%|██████████████████████████████▋                                                                                    | 1080/4050 [04:27<11:15,  4.40it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 30%|██████████████████████████████████▌                                                                                | 1215/4050 [04:57<10:25,  4.53it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 33%|██████████████████████████████████████▎                                                                            | 1350/4050 [05:27<09:49,  4.58it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 37%|██████████████████████████████████████████▏                                                                        | 1485/4050 [05:57<09:15,  4.62it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 37%|██████████████████████████████████████████▌                                                                        | 1500/4050 [06:01<17:32,  2.42it/s]Saving model checkpoint to models/checkpoint-1500
Configuration saved in models/checkpoint-1500/config.json
Model weights saved in models/checkpoint-1500/pytorch_model.bin
tokenizer config file saved in models/checkpoint-1500/tokenizer_config.json
Special tokens file saved in models/checkpoint-1500/special_tokens_map.json
 40%|██████████████████████████████████████████████                                                                     | 1620/4050 [06:37<08:46,  4.62it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 43%|█████████████████████████████████████████████████▊                                                                 | 1755/4050 [07:07<08:23,  4.56it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 47%|█████████████████████████████████████████████████████▋                                                             | 1890/4050 [07:37<07:49,  4.60it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 49%|████████████████████████████████████████████████████████▊                                                          | 2000/4050 [08:01<14:02,  2.43it/s]Saving model checkpoint to models/checkpoint-2000
Configuration saved in models/checkpoint-2000/config.json
Model weights saved in models/checkpoint-2000/pytorch_model.bin
tokenizer config file saved in models/checkpoint-2000/tokenizer_config.json
Special tokens file saved in models/checkpoint-2000/special_tokens_map.json
 50%|█████████████████████████████████████████████████████████▌                                                         | 2025/4050 [08:17<07:19,  4.61it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 53%|█████████████████████████████████████████████████████████████▎                                                     | 2160/4050 [08:46<06:49,  4.62it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 57%|█████████████████████████████████████████████████████████████████▏                                                 | 2295/4050 [09:16<06:21,  4.60it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 60%|█████████████████████████████████████████████████████████████████████                                              | 2430/4050 [09:46<05:50,  4.63it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 62%|██████████████████████████████████████████████████████████████████████▉                                            | 2500/4050 [10:02<10:42,  2.41it/s]Saving model checkpoint to models/checkpoint-2500
Configuration saved in models/checkpoint-2500/config.json
Model weights saved in models/checkpoint-2500/pytorch_model.bin
tokenizer config file saved in models/checkpoint-2500/tokenizer_config.json
Special tokens file saved in models/checkpoint-2500/special_tokens_map.json
 63%|████████████████████████████████████████████████████████████████████████▊                                          | 2565/4050 [10:26<05:22,  4.61it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 67%|████████████████████████████████████████████████████████████████████████████▋                                      | 2700/4050 [10:56<05:00,  4.49it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 70%|████████████████████████████████████████████████████████████████████████████████▌                                  | 2835/4050 [11:25<04:24,  4.59it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 73%|████████████████████████████████████████████████████████████████████████████████████▎                              | 2970/4050 [11:55<03:52,  4.64it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 74%|█████████████████████████████████████████████████████████████████████████████████████▏                             | 3000/4050 [12:03<07:12,  2.43it/s]Saving model checkpoint to models/checkpoint-3000
Configuration saved in models/checkpoint-3000/config.json
Model weights saved in models/checkpoint-3000/pytorch_model.bin
tokenizer config file saved in models/checkpoint-3000/tokenizer_config.json
Special tokens file saved in models/checkpoint-3000/special_tokens_map.json
 77%|████████████████████████████████████████████████████████████████████████████████████████▏                          | 3105/4050 [12:35<03:25,  4.60it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 80%|████████████████████████████████████████████████████████████████████████████████████████████                       | 3240/4050 [13:04<02:58,  4.54it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 83%|███████████████████████████████████████████████████████████████████████████████████████████████▊                   | 3375/4050 [13:34<02:25,  4.63it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 86%|███████████████████████████████████████████████████████████████████████████████████████████████████▍               | 3500/4050 [14:02<03:45,  2.44it/s]Saving model checkpoint to models/checkpoint-3500
Configuration saved in models/checkpoint-3500/config.json
Model weights saved in models/checkpoint-3500/pytorch_model.bin
tokenizer config file saved in models/checkpoint-3500/tokenizer_config.json
Special tokens file saved in models/checkpoint-3500/special_tokens_map.json
 87%|███████████████████████████████████████████████████████████████████████████████████████████████████▋               | 3510/4050 [14:14<03:04,  2.92it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████▌           | 3645/4050 [14:44<01:27,  4.61it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▎       | 3780/4050 [15:13<00:58,  4.63it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▏   | 3915/4050 [15:43<00:29,  4.61it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌ | 4000/4050 [16:02<00:20,  2.44it/s]Saving model checkpoint to models/checkpoint-4000
Configuration saved in models/checkpoint-4000/config.json
Model weights saved in models/checkpoint-4000/pytorch_model.bin
tokenizer config file saved in models/checkpoint-4000/tokenizer_config.json
Special tokens file saved in models/checkpoint-4000/special_tokens_map.json
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4050/4050 [16:24<00:00,  4.62it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4050/4050 [16:24<00:00,  4.62it/s]
Training completed. Do not forget to share your model on huggingface.co/models =)
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4050/4050 [16:24<00:00,  4.11it/s]