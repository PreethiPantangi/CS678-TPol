{'eval_loss': 0.12329137325286865, 'eval_runtime': 0.3321, 'eval_samples_per_second': 180.694, 'eval_steps_per_second': 45.174, 'epoch': 1.0}
{'eval_loss': 0.11073578149080276, 'eval_runtime': 0.3325, 'eval_samples_per_second': 180.476, 'eval_steps_per_second': 45.119, 'epoch': 2.0}
{'eval_loss': 0.07206272333860397, 'eval_runtime': 0.3343, 'eval_samples_per_second': 179.477, 'eval_steps_per_second': 44.869, 'epoch': 3.0}
{'loss': 0.455, 'learning_rate': 8.765432098765432e-06, 'epoch': 3.7}
{'eval_loss': 0.07789647579193115, 'eval_runtime': 0.3304, 'eval_samples_per_second': 181.578, 'eval_steps_per_second': 45.395, 'epoch': 4.0}
{'eval_loss': 0.07001244276762009, 'eval_runtime': 0.3332, 'eval_samples_per_second': 180.095, 'eval_steps_per_second': 45.024, 'epoch': 5.0}
{'eval_loss': 0.11128759384155273, 'eval_runtime': 0.3333, 'eval_samples_per_second': 180.035, 'eval_steps_per_second': 45.009, 'epoch': 6.0}
{'eval_loss': 0.0848761722445488, 'eval_runtime': 0.3306, 'eval_samples_per_second': 181.471, 'eval_steps_per_second': 45.368, 'epoch': 7.0}
{'loss': 0.0064, 'learning_rate': 7.530864197530865e-06, 'epoch': 7.41}
{'eval_loss': 0.12327222526073456, 'eval_runtime': 0.334, 'eval_samples_per_second': 179.647, 'eval_steps_per_second': 44.912, 'epoch': 8.0}
{'eval_loss': 0.09904024749994278, 'eval_runtime': 0.3319, 'eval_samples_per_second': 180.754, 'eval_steps_per_second': 45.189, 'epoch': 9.0}
{'eval_loss': 0.09714837372303009, 'eval_runtime': 0.3348, 'eval_samples_per_second': 179.187, 'eval_steps_per_second': 44.797, 'epoch': 10.0}
{'eval_loss': 0.06442298740148544, 'eval_runtime': 0.3295, 'eval_samples_per_second': 182.075, 'eval_steps_per_second': 45.519, 'epoch': 11.0}
{'loss': 0.0046, 'learning_rate': 6.296296296296297e-06, 'epoch': 11.11}
{'eval_loss': 0.0693797618150711, 'eval_runtime': 0.3326, 'eval_samples_per_second': 180.402, 'eval_steps_per_second': 45.101, 'epoch': 12.0}
{'eval_loss': 0.07511840015649796, 'eval_runtime': 0.3364, 'eval_samples_per_second': 178.369, 'eval_steps_per_second': 44.592, 'epoch': 13.0}
{'eval_loss': 0.057239241898059845, 'eval_runtime': 0.3314, 'eval_samples_per_second': 181.048, 'eval_steps_per_second': 45.262, 'epoch': 14.0}
{'loss': 0.0036, 'learning_rate': 5.061728395061729e-06, 'epoch': 14.81}
{'eval_loss': 0.06450530886650085, 'eval_runtime': 0.3334, 'eval_samples_per_second': 179.944, 'eval_steps_per_second': 44.986, 'epoch': 15.0}
{'eval_loss': 0.08644214272499084, 'eval_runtime': 0.3296, 'eval_samples_per_second': 182.021, 'eval_steps_per_second': 45.505, 'epoch': 16.0}
{'eval_loss': 0.080243319272995, 'eval_runtime': 0.3317, 'eval_samples_per_second': 180.91, 'eval_steps_per_second': 45.228, 'epoch': 17.0}
{'eval_loss': 0.07514327019453049, 'eval_runtime': 0.3295, 'eval_samples_per_second': 182.081, 'eval_steps_per_second': 45.52, 'epoch': 18.0}
{'loss': 0.0007, 'learning_rate': 3.827160493827161e-06, 'epoch': 18.52}
{'eval_loss': 0.07312794774770737, 'eval_runtime': 0.3303, 'eval_samples_per_second': 181.63, 'eval_steps_per_second': 45.408, 'epoch': 19.0}
{'eval_loss': 0.07515530288219452, 'eval_runtime': 0.3321, 'eval_samples_per_second': 180.69, 'eval_steps_per_second': 45.173, 'epoch': 20.0}
{'eval_loss': 0.08836299926042557, 'eval_runtime': 0.332, 'eval_samples_per_second': 180.711, 'eval_steps_per_second': 45.178, 'epoch': 21.0}
{'eval_loss': 0.08501169085502625, 'eval_runtime': 0.3312, 'eval_samples_per_second': 181.183, 'eval_steps_per_second': 45.296, 'epoch': 22.0}
{'loss': 0.0004, 'learning_rate': 2.5925925925925925e-06, 'epoch': 22.22}
{'eval_loss': 0.08382978290319443, 'eval_runtime': 0.3321, 'eval_samples_per_second': 180.685, 'eval_steps_per_second': 45.171, 'epoch': 23.0}
{'eval_loss': 0.08375570178031921, 'eval_runtime': 0.3289, 'eval_samples_per_second': 182.453, 'eval_steps_per_second': 45.613, 'epoch': 24.0}
{'eval_loss': 0.08393402397632599, 'eval_runtime': 0.3318, 'eval_samples_per_second': 180.838, 'eval_steps_per_second': 45.21, 'epoch': 25.0}
{'loss': 0.0, 'learning_rate': 1.3580246913580248e-06, 'epoch': 25.93}
{'eval_loss': 0.08406443893909454, 'eval_runtime': 0.3307, 'eval_samples_per_second': 181.454, 'eval_steps_per_second': 45.364, 'epoch': 26.0}
{'eval_loss': 0.08447296917438507, 'eval_runtime': 0.3308, 'eval_samples_per_second': 181.365, 'eval_steps_per_second': 45.341, 'epoch': 27.0}
{'eval_loss': 0.08464465290307999, 'eval_runtime': 0.3295, 'eval_samples_per_second': 182.07, 'eval_steps_per_second': 45.517, 'epoch': 28.0}
{'eval_loss': 0.08465048670768738, 'eval_runtime': 0.3326, 'eval_samples_per_second': 180.383, 'eval_steps_per_second': 45.096, 'epoch': 29.0}
{'loss': 0.0, 'learning_rate': 1.234567901234568e-07, 'epoch': 29.63}
{'eval_loss': 0.084662064909935, 'eval_runtime': 0.3316, 'eval_samples_per_second': 180.945, 'eval_steps_per_second': 45.236, 'epoch': 30.0}
{'train_runtime': 985.2373, 'train_samples_per_second': 16.443, 'train_steps_per_second': 4.111, 'train_loss': 0.058112234519162205, 'epoch': 30.0}
EXACT-MATCH ACCURACY
ACC: 16.43%
MN: 17.79%
NMN: 14.53%
NO. CORRECT TOKENS
ACC: 44.24%
MN: 44.50%
NMN: 43.87%
MAX CORRECT SPAN
ACC: 55.05%
MN: 55.13%
NMN: 54.94%
  3%|███▊                                                                                                                | 135/4050 [00:32<14:20,  4.55it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
  7%|███████▋                                                                                                            | 270/4050 [01:02<14:03,  4.48it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 10%|███████████▌                                                                                                        | 405/4050 [01:32<13:09,  4.62it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 12%|██████████████▎                                                                                                     | 500/4050 [01:53<24:39,  2.40it/s]Saving model checkpoint to models/checkpoint-500
Configuration saved in models/checkpoint-500/config.json
Model weights saved in models/checkpoint-500/pytorch_model.bin
tokenizer config file saved in models/checkpoint-500/tokenizer_config.json
Special tokens file saved in models/checkpoint-500/special_tokens_map.json
 13%|███████████████▍                                                                                                    | 540/4050 [02:12<12:40,  4.62it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 17%|███████████████████▎                                                                                                | 675/4050 [02:41<12:21,  4.55it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 20%|███████████████████████▏                                                                                            | 810/4050 [03:11<11:43,  4.60it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 23%|███████████████████████████                                                                                         | 945/4050 [03:41<11:12,  4.62it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 25%|████████████████████████████▍                                                                                      | 1000/4050 [03:54<21:27,  2.37it/s]Saving model checkpoint to models/checkpoint-1000
Configuration saved in models/checkpoint-1000/config.json
Model weights saved in models/checkpoint-1000/pytorch_model.bin
tokenizer config file saved in models/checkpoint-1000/tokenizer_config.json
Special tokens file saved in models/checkpoint-1000/special_tokens_map.json
 27%|██████████████████████████████▋                                                                                    | 1080/4050 [04:21<10:46,  4.60it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 30%|██████████████████████████████████▌                                                                                | 1215/4050 [04:51<10:21,  4.56it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 33%|██████████████████████████████████████▎                                                                            | 1350/4050 [05:21<09:45,  4.61it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 37%|██████████████████████████████████████████▏                                                                        | 1485/4050 [05:50<09:15,  4.62it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 37%|██████████████████████████████████████████▌                                                                        | 1500/4050 [05:55<17:41,  2.40it/s]Saving model checkpoint to models/checkpoint-1500
Configuration saved in models/checkpoint-1500/config.json
Model weights saved in models/checkpoint-1500/pytorch_model.bin
tokenizer config file saved in models/checkpoint-1500/tokenizer_config.json
Special tokens file saved in models/checkpoint-1500/special_tokens_map.json
 40%|██████████████████████████████████████████████                                                                     | 1620/4050 [06:31<08:45,  4.62it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 43%|█████████████████████████████████████████████████▊                                                                 | 1755/4050 [07:00<08:18,  4.60it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 47%|█████████████████████████████████████████████████████▋                                                             | 1890/4050 [07:30<07:48,  4.61it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 49%|████████████████████████████████████████████████████████▊                                                          | 2000/4050 [07:55<16:04,  2.12it/s]Saving model checkpoint to models/checkpoint-2000
Configuration saved in models/checkpoint-2000/config.json
Model weights saved in models/checkpoint-2000/pytorch_model.bin
tokenizer config file saved in models/checkpoint-2000/tokenizer_config.json
Special tokens file saved in models/checkpoint-2000/special_tokens_map.json
 50%|█████████████████████████████████████████████████████████▌                                                         | 2025/4050 [08:11<07:21,  4.59it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 53%|█████████████████████████████████████████████████████████████▎                                                     | 2160/4050 [08:41<06:49,  4.62it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 57%|█████████████████████████████████████████████████████████████████▏                                                 | 2295/4050 [09:10<06:20,  4.61it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 60%|█████████████████████████████████████████████████████████████████████                                              | 2430/4050 [09:40<05:48,  4.64it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 62%|██████████████████████████████████████████████████████████████████████▉                                            | 2500/4050 [09:56<10:44,  2.41it/s]Saving model checkpoint to models/checkpoint-2500
Configuration saved in models/checkpoint-2500/config.json
Model weights saved in models/checkpoint-2500/pytorch_model.bin
tokenizer config file saved in models/checkpoint-2500/tokenizer_config.json
Special tokens file saved in models/checkpoint-2500/special_tokens_map.json
 63%|████████████████████████████████████████████████████████████████████████▊                                          | 2565/4050 [10:21<05:22,  4.60it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 67%|████████████████████████████████████████████████████████████████████████████▋                                      | 2700/4050 [10:50<04:51,  4.63it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 70%|████████████████████████████████████████████████████████████████████████████████▌                                  | 2835/4050 [11:20<04:23,  4.62it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 73%|████████████████████████████████████████████████████████████████████████████████████▎                              | 2970/4050 [11:50<03:52,  4.64it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 74%|█████████████████████████████████████████████████████████████████████████████████████▏                             | 3000/4050 [11:57<07:14,  2.42it/s]Saving model checkpoint to models/checkpoint-3000
Configuration saved in models/checkpoint-3000/config.json
Model weights saved in models/checkpoint-3000/pytorch_model.bin
tokenizer config file saved in models/checkpoint-3000/tokenizer_config.json
Special tokens file saved in models/checkpoint-3000/special_tokens_map.json
 77%|████████████████████████████████████████████████████████████████████████████████████████▏                          | 3105/4050 [12:29<03:24,  4.63it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 80%|████████████████████████████████████████████████████████████████████████████████████████████                       | 3240/4050 [12:59<02:55,  4.62it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 83%|███████████████████████████████████████████████████████████████████████████████████████████████▊                   | 3375/4050 [13:28<02:26,  4.62it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 86%|███████████████████████████████████████████████████████████████████████████████████████████████████▍               | 3500/4050 [13:57<03:46,  2.43it/s]Saving model checkpoint to models/checkpoint-3500
Configuration saved in models/checkpoint-3500/config.json
Model weights saved in models/checkpoint-3500/pytorch_model.bin
tokenizer config file saved in models/checkpoint-3500/tokenizer_config.json
Special tokens file saved in models/checkpoint-3500/special_tokens_map.json
 87%|███████████████████████████████████████████████████████████████████████████████████████████████████▋               | 3510/4050 [14:08<03:01,  2.97it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████▌           | 3645/4050 [14:38<01:27,  4.63it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▎       | 3780/4050 [15:07<00:58,  4.61it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▏   | 3915/4050 [15:37<00:29,  4.61it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌ | 4000/4050 [15:56<00:20,  2.43it/s]Saving model checkpoint to models/checkpoint-4000
Configuration saved in models/checkpoint-4000/config.json
Model weights saved in models/checkpoint-4000/pytorch_model.bin
tokenizer config file saved in models/checkpoint-4000/tokenizer_config.json
Special tokens file saved in models/checkpoint-4000/special_tokens_map.json
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4050/4050 [16:17<00:00,  4.61it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4050/4050 [16:17<00:00,  4.61it/s]
Training completed. Do not forget to share your model on huggingface.co/models =)
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4050/4050 [16:17<00:00,  4.14it/s]