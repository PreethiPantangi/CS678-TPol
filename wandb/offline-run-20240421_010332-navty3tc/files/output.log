{'eval_loss': 2.4674925804138184, 'eval_runtime': 0.3344, 'eval_samples_per_second': 179.439, 'eval_steps_per_second': 44.86, 'epoch': 1.0}
{'eval_loss': 0.3485320508480072, 'eval_runtime': 0.3356, 'eval_samples_per_second': 178.792, 'eval_steps_per_second': 44.698, 'epoch': 2.0}
{'eval_loss': 0.2806738018989563, 'eval_runtime': 0.3367, 'eval_samples_per_second': 178.222, 'eval_steps_per_second': 44.555, 'epoch': 3.0}
{'loss': 1.5052, 'learning_rate': 8.765432098765432e-06, 'epoch': 3.7}
{'eval_loss': 0.19407545030117035, 'eval_runtime': 0.3322, 'eval_samples_per_second': 180.604, 'eval_steps_per_second': 45.151, 'epoch': 4.0}
{'eval_loss': 0.2815724313259125, 'eval_runtime': 0.3329, 'eval_samples_per_second': 180.229, 'eval_steps_per_second': 45.057, 'epoch': 5.0}
{'eval_loss': 0.20912925899028778, 'eval_runtime': 0.3331, 'eval_samples_per_second': 180.107, 'eval_steps_per_second': 45.027, 'epoch': 6.0}
{'eval_loss': 0.1941080391407013, 'eval_runtime': 0.3359, 'eval_samples_per_second': 178.62, 'eval_steps_per_second': 44.655, 'epoch': 7.0}
{'loss': 0.0413, 'learning_rate': 7.530864197530865e-06, 'epoch': 7.41}
{'eval_loss': 0.2200876921415329, 'eval_runtime': 0.3345, 'eval_samples_per_second': 179.356, 'eval_steps_per_second': 44.839, 'epoch': 8.0}
{'eval_loss': 0.21721799671649933, 'eval_runtime': 0.3332, 'eval_samples_per_second': 180.08, 'eval_steps_per_second': 45.02, 'epoch': 9.0}
{'eval_loss': 0.20740661025047302, 'eval_runtime': 0.3341, 'eval_samples_per_second': 179.573, 'eval_steps_per_second': 44.893, 'epoch': 10.0}
{'eval_loss': 0.2232961356639862, 'eval_runtime': 0.3327, 'eval_samples_per_second': 180.33, 'eval_steps_per_second': 45.082, 'epoch': 11.0}
{'loss': 0.0208, 'learning_rate': 6.296296296296297e-06, 'epoch': 11.11}
{'eval_loss': 0.2123025506734848, 'eval_runtime': 0.3324, 'eval_samples_per_second': 180.496, 'eval_steps_per_second': 45.124, 'epoch': 12.0}
{'eval_loss': 0.23847974836826324, 'eval_runtime': 0.3374, 'eval_samples_per_second': 177.814, 'eval_steps_per_second': 44.453, 'epoch': 13.0}
{'eval_loss': 0.22977755963802338, 'eval_runtime': 0.3374, 'eval_samples_per_second': 177.814, 'eval_steps_per_second': 44.454, 'epoch': 14.0}
{'loss': 0.0096, 'learning_rate': 5.061728395061729e-06, 'epoch': 14.81}
{'eval_loss': 0.24683254957199097, 'eval_runtime': 0.338, 'eval_samples_per_second': 177.503, 'eval_steps_per_second': 44.376, 'epoch': 15.0}
{'eval_loss': 0.23052038252353668, 'eval_runtime': 0.3327, 'eval_samples_per_second': 180.358, 'eval_steps_per_second': 45.089, 'epoch': 16.0}
{'eval_loss': 0.23327353596687317, 'eval_runtime': 0.3352, 'eval_samples_per_second': 179.009, 'eval_steps_per_second': 44.752, 'epoch': 17.0}
{'eval_loss': 0.24808229506015778, 'eval_runtime': 0.3345, 'eval_samples_per_second': 179.38, 'eval_steps_per_second': 44.845, 'epoch': 18.0}
{'loss': 0.0058, 'learning_rate': 3.827160493827161e-06, 'epoch': 18.52}
{'eval_loss': 0.2665344476699829, 'eval_runtime': 0.3348, 'eval_samples_per_second': 179.206, 'eval_steps_per_second': 44.802, 'epoch': 19.0}
{'eval_loss': 0.2640071511268616, 'eval_runtime': 0.3344, 'eval_samples_per_second': 179.446, 'eval_steps_per_second': 44.861, 'epoch': 20.0}
{'eval_loss': 0.2815615236759186, 'eval_runtime': 0.3389, 'eval_samples_per_second': 177.019, 'eval_steps_per_second': 44.255, 'epoch': 21.0}
{'eval_loss': 0.24879029393196106, 'eval_runtime': 0.334, 'eval_samples_per_second': 179.622, 'eval_steps_per_second': 44.906, 'epoch': 22.0}
{'loss': 0.0032, 'learning_rate': 2.5925925925925925e-06, 'epoch': 22.22}
{'eval_loss': 0.26056793332099915, 'eval_runtime': 0.3298, 'eval_samples_per_second': 181.95, 'eval_steps_per_second': 45.487, 'epoch': 23.0}
{'eval_loss': 0.2660045027732849, 'eval_runtime': 0.3289, 'eval_samples_per_second': 182.437, 'eval_steps_per_second': 45.609, 'epoch': 24.0}
{'eval_loss': 0.27704915404319763, 'eval_runtime': 0.3392, 'eval_samples_per_second': 176.884, 'eval_steps_per_second': 44.221, 'epoch': 25.0}
{'loss': 0.0015, 'learning_rate': 1.3580246913580248e-06, 'epoch': 25.93}
{'eval_loss': 0.279069721698761, 'eval_runtime': 0.3365, 'eval_samples_per_second': 178.293, 'eval_steps_per_second': 44.573, 'epoch': 26.0}
{'eval_loss': 0.2857808768749237, 'eval_runtime': 0.3342, 'eval_samples_per_second': 179.537, 'eval_steps_per_second': 44.884, 'epoch': 27.0}
{'eval_loss': 0.28552767634391785, 'eval_runtime': 0.3324, 'eval_samples_per_second': 180.512, 'eval_steps_per_second': 45.128, 'epoch': 28.0}
{'eval_loss': 0.2864700257778168, 'eval_runtime': 0.3317, 'eval_samples_per_second': 180.912, 'eval_steps_per_second': 45.228, 'epoch': 29.0}
{'loss': 0.0007, 'learning_rate': 1.234567901234568e-07, 'epoch': 29.63}
{'eval_loss': 0.2871702313423157, 'eval_runtime': 0.3303, 'eval_samples_per_second': 181.637, 'eval_steps_per_second': 45.409, 'epoch': 30.0}
{'train_runtime': 1063.9966, 'train_samples_per_second': 15.226, 'train_steps_per_second': 3.806, 'train_loss': 0.19607292041596439, 'epoch': 30.0}
EXACT-MATCH ACCURACY
ACC: 17.86%
MN: 20.25%
NMN: 14.53%
NO. CORRECT TOKENS
ACC: 47.35%
MN: 49.07%
NMN: 44.93%
MAX CORRECT SPAN
ACC: 55.93%
MN: 59.16%
NMN: 51.38%
  3%|███▊                                                                                                                | 135/4050 [00:31<14:55,  4.37it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
  7%|███████▋                                                                                                            | 270/4050 [01:02<14:28,  4.35it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 10%|███████████▌                                                                                                        | 405/4050 [01:34<13:54,  4.37it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 12%|██████████████▎                                                                                                     | 500/4050 [01:56<25:03,  2.36it/s]Saving model checkpoint to models/checkpoint-500
Configuration saved in models/checkpoint-500/config.json
Model weights saved in models/checkpoint-500/pytorch_model.bin
tokenizer config file saved in models/checkpoint-500/tokenizer_config.json
Special tokens file saved in models/checkpoint-500/special_tokens_map.json
 13%|███████████████▍                                                                                                    | 540/4050 [02:15<13:00,  4.50it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 17%|███████████████████▎                                                                                                | 675/4050 [02:46<12:46,  4.40it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 20%|███████████████████████▏                                                                                            | 810/4050 [03:16<12:11,  4.43it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 23%|███████████████████████████                                                                                         | 945/4050 [03:47<11:26,  4.52it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 25%|████████████████████████████▍                                                                                      | 1000/4050 [04:00<21:02,  2.42it/s]Saving model checkpoint to models/checkpoint-1000
Configuration saved in models/checkpoint-1000/config.json
Model weights saved in models/checkpoint-1000/pytorch_model.bin
tokenizer config file saved in models/checkpoint-1000/tokenizer_config.json
Special tokens file saved in models/checkpoint-1000/special_tokens_map.json
 27%|██████████████████████████████▋                                                                                    | 1080/4050 [04:27<10:59,  4.50it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 30%|██████████████████████████████████▌                                                                                | 1215/4050 [04:58<10:20,  4.57it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 33%|██████████████████████████████████████▎                                                                            | 1350/4050 [05:28<10:03,  4.47it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 37%|██████████████████████████████████████████▏                                                                        | 1485/4050 [05:58<09:32,  4.48it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 37%|██████████████████████████████████████████▌                                                                        | 1500/4050 [06:02<17:34,  2.42it/s]Saving model checkpoint to models/checkpoint-1500
Configuration saved in models/checkpoint-1500/config.json
Model weights saved in models/checkpoint-1500/pytorch_model.bin
tokenizer config file saved in models/checkpoint-1500/tokenizer_config.json
Special tokens file saved in models/checkpoint-1500/special_tokens_map.json
 40%|██████████████████████████████████████████████                                                                     | 1620/4050 [06:37<08:48,  4.60it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 43%|█████████████████████████████████████████████████▊                                                                 | 1755/4050 [07:07<08:17,  4.61it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 47%|█████████████████████████████████████████████████████▋                                                             | 1890/4050 [07:37<07:49,  4.60it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 49%|████████████████████████████████████████████████████████▊                                                          | 2000/4050 [08:02<14:05,  2.42it/s]Saving model checkpoint to models/checkpoint-2000
Configuration saved in models/checkpoint-2000/config.json
Model weights saved in models/checkpoint-2000/pytorch_model.bin
tokenizer config file saved in models/checkpoint-2000/tokenizer_config.json
Special tokens file saved in models/checkpoint-2000/special_tokens_map.json
 50%|█████████████████████████████████████████████████████████▌                                                         | 2025/4050 [08:17<07:21,  4.58it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 53%|█████████████████████████████████████████████████████████████▎                                                     | 2160/4050 [08:47<06:52,  4.58it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 57%|█████████████████████████████████████████████████████████████████▏                                                 | 2295/4050 [09:17<06:23,  4.58it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 60%|█████████████████████████████████████████████████████████████████████                                              | 2430/4050 [09:47<05:50,  4.62it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 62%|██████████████████████████████████████████████████████████████████████▉                                            | 2500/4050 [10:03<10:31,  2.46it/s]Saving model checkpoint to models/checkpoint-2500
Configuration saved in models/checkpoint-2500/config.json
Model weights saved in models/checkpoint-2500/pytorch_model.bin
tokenizer config file saved in models/checkpoint-2500/tokenizer_config.json
Special tokens file saved in models/checkpoint-2500/special_tokens_map.json
 63%|████████████████████████████████████████████████████████████████████████▊                                          | 2565/4050 [10:27<05:30,  4.49it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 67%|████████████████████████████████████████████████████████████████████████████▋                                      | 2700/4050 [10:57<04:52,  4.61it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 70%|████████████████████████████████████████████████████████████████████████████████▌                                  | 2835/4050 [11:27<04:26,  4.56it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 73%|████████████████████████████████████████████████████████████████████████████████████▎                              | 2970/4050 [11:56<03:54,  4.61it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 74%|█████████████████████████████████████████████████████████████████████████████████████▏                             | 3000/4050 [12:04<07:04,  2.47it/s]Saving model checkpoint to models/checkpoint-3000
Configuration saved in models/checkpoint-3000/config.json
Model weights saved in models/checkpoint-3000/pytorch_model.bin
tokenizer config file saved in models/checkpoint-3000/tokenizer_config.json
Special tokens file saved in models/checkpoint-3000/special_tokens_map.json
 77%|████████████████████████████████████████████████████████████████████████████████████████▏                          | 3105/4050 [12:36<03:23,  4.63it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 80%|████████████████████████████████████████████████████████████████████████████████████████████                       | 3240/4050 [13:06<02:55,  4.60it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 83%|███████████████████████████████████████████████████████████████████████████████████████████████▊                   | 3375/4050 [13:36<02:25,  4.62it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 86%|███████████████████████████████████████████████████████████████████████████████████████████████████▍               | 3500/4050 [14:04<03:43,  2.46it/s]Saving model checkpoint to models/checkpoint-3500
Configuration saved in models/checkpoint-3500/config.json
Model weights saved in models/checkpoint-3500/pytorch_model.bin
tokenizer config file saved in models/checkpoint-3500/tokenizer_config.json
Special tokens file saved in models/checkpoint-3500/special_tokens_map.json
 87%|███████████████████████████████████████████████████████████████████████████████████████████████████▋               | 3510/4050 [14:17<03:10,  2.83it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████▌           | 3645/4050 [14:46<01:27,  4.61it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▎       | 3780/4050 [15:16<00:58,  4.65it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▏   | 3915/4050 [15:46<00:29,  4.62it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌ | 4000/4050 [16:05<00:20,  2.44it/s]Saving model checkpoint to models/checkpoint-4000
Configuration saved in models/checkpoint-4000/config.json
Model weights saved in models/checkpoint-4000/pytorch_model.bin
tokenizer config file saved in models/checkpoint-4000/tokenizer_config.json
Special tokens file saved in models/checkpoint-4000/special_tokens_map.json
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4050/4050 [16:26<00:00,  4.57it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4050/4050 [16:26<00:00,  4.57it/s]
Training completed. Do not forget to share your model on huggingface.co/models =)
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4050/4050 [16:26<00:00,  4.10it/s]