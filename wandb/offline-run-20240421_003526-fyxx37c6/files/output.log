{'eval_loss': 0.12838125228881836, 'eval_runtime': 0.3362, 'eval_samples_per_second': 178.455, 'eval_steps_per_second': 44.614, 'epoch': 1.0}
{'eval_loss': 0.050413746386766434, 'eval_runtime': 0.3339, 'eval_samples_per_second': 179.712, 'eval_steps_per_second': 44.928, 'epoch': 2.0}
{'eval_loss': 0.025924213230609894, 'eval_runtime': 0.3334, 'eval_samples_per_second': 179.989, 'eval_steps_per_second': 44.997, 'epoch': 3.0}
{'loss': 0.5737, 'learning_rate': 8.765432098765432e-06, 'epoch': 3.7}
{'eval_loss': 0.01919645629823208, 'eval_runtime': 0.337, 'eval_samples_per_second': 178.061, 'eval_steps_per_second': 44.515, 'epoch': 4.0}
{'eval_loss': 0.028686342760920525, 'eval_runtime': 0.3373, 'eval_samples_per_second': 177.864, 'eval_steps_per_second': 44.466, 'epoch': 5.0}
{'eval_loss': 0.015674984082579613, 'eval_runtime': 0.3354, 'eval_samples_per_second': 178.894, 'eval_steps_per_second': 44.723, 'epoch': 6.0}
{'eval_loss': 0.014317044988274574, 'eval_runtime': 0.3344, 'eval_samples_per_second': 179.405, 'eval_steps_per_second': 44.851, 'epoch': 7.0}
{'loss': 0.0074, 'learning_rate': 7.530864197530865e-06, 'epoch': 7.41}
{'eval_loss': 0.015841154381632805, 'eval_runtime': 0.3347, 'eval_samples_per_second': 179.276, 'eval_steps_per_second': 44.819, 'epoch': 8.0}
{'eval_loss': 0.010571138933300972, 'eval_runtime': 0.3355, 'eval_samples_per_second': 178.82, 'eval_steps_per_second': 44.705, 'epoch': 9.0}
{'eval_loss': 0.012668277136981487, 'eval_runtime': 0.3349, 'eval_samples_per_second': 179.137, 'eval_steps_per_second': 44.784, 'epoch': 10.0}
{'eval_loss': 0.006308540236204863, 'eval_runtime': 0.3352, 'eval_samples_per_second': 178.981, 'eval_steps_per_second': 44.745, 'epoch': 11.0}
{'loss': 0.005, 'learning_rate': 6.296296296296297e-06, 'epoch': 11.11}
{'eval_loss': 0.005668389145284891, 'eval_runtime': 0.3345, 'eval_samples_per_second': 179.36, 'eval_steps_per_second': 44.84, 'epoch': 12.0}
{'eval_loss': 0.004866783507168293, 'eval_runtime': 0.334, 'eval_samples_per_second': 179.62, 'eval_steps_per_second': 44.905, 'epoch': 13.0}
{'eval_loss': 0.004222522489726543, 'eval_runtime': 0.3372, 'eval_samples_per_second': 177.925, 'eval_steps_per_second': 44.481, 'epoch': 14.0}
{'loss': 0.0009, 'learning_rate': 5.061728395061729e-06, 'epoch': 14.81}
{'eval_loss': 0.0031812558881938457, 'eval_runtime': 0.335, 'eval_samples_per_second': 179.128, 'eval_steps_per_second': 44.782, 'epoch': 15.0}
{'eval_loss': 0.005347291473299265, 'eval_runtime': 0.336, 'eval_samples_per_second': 178.558, 'eval_steps_per_second': 44.64, 'epoch': 16.0}
{'eval_loss': 0.004300658591091633, 'eval_runtime': 0.3359, 'eval_samples_per_second': 178.637, 'eval_steps_per_second': 44.659, 'epoch': 17.0}
{'eval_loss': 0.004328134469687939, 'eval_runtime': 0.3362, 'eval_samples_per_second': 178.484, 'eval_steps_per_second': 44.621, 'epoch': 18.0}
{'loss': 0.001, 'learning_rate': 3.827160493827161e-06, 'epoch': 18.52}
{'eval_loss': 0.0050025503151118755, 'eval_runtime': 0.3371, 'eval_samples_per_second': 177.988, 'eval_steps_per_second': 44.497, 'epoch': 19.0}
{'eval_loss': 0.004905502311885357, 'eval_runtime': 0.3354, 'eval_samples_per_second': 178.917, 'eval_steps_per_second': 44.729, 'epoch': 20.0}
{'eval_loss': 0.006066085770726204, 'eval_runtime': 0.3352, 'eval_samples_per_second': 179.007, 'eval_steps_per_second': 44.752, 'epoch': 21.0}
{'eval_loss': 0.005537925288081169, 'eval_runtime': 0.3351, 'eval_samples_per_second': 179.035, 'eval_steps_per_second': 44.759, 'epoch': 22.0}
{'loss': 0.0009, 'learning_rate': 2.5925925925925925e-06, 'epoch': 22.22}
{'eval_loss': 0.00663757836446166, 'eval_runtime': 0.3378, 'eval_samples_per_second': 177.645, 'eval_steps_per_second': 44.411, 'epoch': 23.0}
{'eval_loss': 0.005504406522959471, 'eval_runtime': 0.3365, 'eval_samples_per_second': 178.317, 'eval_steps_per_second': 44.579, 'epoch': 24.0}
{'eval_loss': 0.00587789062410593, 'eval_runtime': 0.3358, 'eval_samples_per_second': 178.687, 'eval_steps_per_second': 44.672, 'epoch': 25.0}
{'loss': 0.0003, 'learning_rate': 1.3580246913580248e-06, 'epoch': 25.93}
{'eval_loss': 0.005294634494930506, 'eval_runtime': 0.3362, 'eval_samples_per_second': 178.452, 'eval_steps_per_second': 44.613, 'epoch': 26.0}
{'eval_loss': 0.006523200776427984, 'eval_runtime': 0.3347, 'eval_samples_per_second': 179.27, 'eval_steps_per_second': 44.817, 'epoch': 27.0}
{'eval_loss': 0.006654710043221712, 'eval_runtime': 0.3355, 'eval_samples_per_second': 178.817, 'eval_steps_per_second': 44.704, 'epoch': 28.0}
{'eval_loss': 0.0066316756419837475, 'eval_runtime': 0.3346, 'eval_samples_per_second': 179.322, 'eval_steps_per_second': 44.83, 'epoch': 29.0}
{'loss': 0.0007, 'learning_rate': 1.234567901234568e-07, 'epoch': 29.63}
{'eval_loss': 0.006626675836741924, 'eval_runtime': 0.3332, 'eval_samples_per_second': 180.09, 'eval_steps_per_second': 45.023, 'epoch': 30.0}
{'train_runtime': 988.0553, 'train_samples_per_second': 16.396, 'train_steps_per_second': 4.099, 'train_loss': 0.0728292743093945, 'epoch': 30.0}
EXACT-MATCH ACCURACY
ACC: 18.93%
MN: 18.06%
NMN: 19.23%
NO. CORRECT TOKENS
ACC: 47.68%
MN: 51.02%
NMN: 46.46%
MAX CORRECT SPAN
ACC: 58.33%
MN: 62.24%
NMN: 56.90%
  3%|███▊                                                                                                                | 135/4050 [00:31<14:48,  4.41it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
  7%|███████▋                                                                                                            | 270/4050 [01:01<14:10,  4.45it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 10%|███████████▌                                                                                                        | 405/4050 [01:31<13:09,  4.62it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 12%|██████████████▎                                                                                                     | 500/4050 [01:53<24:33,  2.41it/s]Saving model checkpoint to models/checkpoint-500
Configuration saved in models/checkpoint-500/config.json
Model weights saved in models/checkpoint-500/pytorch_model.bin
tokenizer config file saved in models/checkpoint-500/tokenizer_config.json
Special tokens file saved in models/checkpoint-500/special_tokens_map.json
 13%|███████████████▍                                                                                                    | 540/4050 [02:12<12:43,  4.60it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 17%|███████████████████▎                                                                                                | 675/4050 [02:42<12:33,  4.48it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 20%|███████████████████████▏                                                                                            | 810/4050 [03:11<11:41,  4.62it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 23%|███████████████████████████                                                                                         | 945/4050 [03:41<11:21,  4.56it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 25%|████████████████████████████▍                                                                                      | 1000/4050 [03:54<21:10,  2.40it/s]Saving model checkpoint to models/checkpoint-1000
Configuration saved in models/checkpoint-1000/config.json
Model weights saved in models/checkpoint-1000/pytorch_model.bin
tokenizer config file saved in models/checkpoint-1000/tokenizer_config.json
Special tokens file saved in models/checkpoint-1000/special_tokens_map.json
 27%|██████████████████████████████▋                                                                                    | 1080/4050 [04:22<10:49,  4.57it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 30%|██████████████████████████████████▌                                                                                | 1215/4050 [04:52<10:14,  4.62it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 33%|██████████████████████████████████████▎                                                                            | 1350/4050 [05:21<09:45,  4.61it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 37%|██████████████████████████████████████████▏                                                                        | 1485/4050 [05:51<09:15,  4.62it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 37%|██████████████████████████████████████████▌                                                                        | 1500/4050 [05:55<17:27,  2.44it/s]Saving model checkpoint to models/checkpoint-1500
Configuration saved in models/checkpoint-1500/config.json
Model weights saved in models/checkpoint-1500/pytorch_model.bin
tokenizer config file saved in models/checkpoint-1500/tokenizer_config.json
Special tokens file saved in models/checkpoint-1500/special_tokens_map.json
 40%|██████████████████████████████████████████████                                                                     | 1620/4050 [06:31<08:45,  4.62it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 43%|█████████████████████████████████████████████████▊                                                                 | 1755/4050 [07:01<08:16,  4.62it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 47%|█████████████████████████████████████████████████████▋                                                             | 1890/4050 [07:31<07:47,  4.62it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 49%|████████████████████████████████████████████████████████▊                                                          | 2000/4050 [07:56<14:07,  2.42it/s]Saving model checkpoint to models/checkpoint-2000
Configuration saved in models/checkpoint-2000/config.json
Model weights saved in models/checkpoint-2000/pytorch_model.bin
tokenizer config file saved in models/checkpoint-2000/tokenizer_config.json
Special tokens file saved in models/checkpoint-2000/special_tokens_map.json
 50%|█████████████████████████████████████████████████████████▌                                                         | 2025/4050 [08:12<07:20,  4.60it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 53%|█████████████████████████████████████████████████████████████▎                                                     | 2160/4050 [08:41<06:50,  4.61it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 57%|█████████████████████████████████████████████████████████████████▏                                                 | 2295/4050 [09:11<06:21,  4.60it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 60%|█████████████████████████████████████████████████████████████████████                                              | 2430/4050 [09:40<05:49,  4.63it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 62%|██████████████████████████████████████████████████████████████████████▉                                            | 2500/4050 [09:57<10:41,  2.41it/s]Saving model checkpoint to models/checkpoint-2500
Configuration saved in models/checkpoint-2500/config.json
Model weights saved in models/checkpoint-2500/pytorch_model.bin
tokenizer config file saved in models/checkpoint-2500/tokenizer_config.json
Special tokens file saved in models/checkpoint-2500/special_tokens_map.json
 63%|████████████████████████████████████████████████████████████████████████▊                                          | 2565/4050 [10:21<05:23,  4.59it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 67%|████████████████████████████████████████████████████████████████████████████▋                                      | 2700/4050 [10:51<04:51,  4.62it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 70%|████████████████████████████████████████████████████████████████████████████████▌                                  | 2835/4050 [11:21<04:23,  4.61it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 73%|████████████████████████████████████████████████████████████████████████████████████▎                              | 2970/4050 [11:50<03:53,  4.63it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 74%|█████████████████████████████████████████████████████████████████████████████████████▏                             | 3000/4050 [11:58<07:16,  2.41it/s]Saving model checkpoint to models/checkpoint-3000
Configuration saved in models/checkpoint-3000/config.json
Model weights saved in models/checkpoint-3000/pytorch_model.bin
tokenizer config file saved in models/checkpoint-3000/tokenizer_config.json
Special tokens file saved in models/checkpoint-3000/special_tokens_map.json
 77%|████████████████████████████████████████████████████████████████████████████████████████▏                          | 3105/4050 [12:31<03:24,  4.62it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 80%|████████████████████████████████████████████████████████████████████████████████████████████                       | 3240/4050 [13:01<02:55,  4.61it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 83%|███████████████████████████████████████████████████████████████████████████████████████████████▊                   | 3375/4050 [13:30<02:26,  4.62it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 86%|███████████████████████████████████████████████████████████████████████████████████████████████████▍               | 3500/4050 [13:58<03:47,  2.42it/s]Saving model checkpoint to models/checkpoint-3500
Configuration saved in models/checkpoint-3500/config.json
Model weights saved in models/checkpoint-3500/pytorch_model.bin
tokenizer config file saved in models/checkpoint-3500/tokenizer_config.json
Special tokens file saved in models/checkpoint-3500/special_tokens_map.json
 87%|███████████████████████████████████████████████████████████████████████████████████████████████████▋               | 3510/4050 [14:11<03:07,  2.89it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████▌           | 3645/4050 [14:40<01:27,  4.62it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▎       | 3780/4050 [15:10<00:58,  4.63it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 97%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▏   | 3915/4050 [15:40<00:29,  4.61it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌ | 4000/4050 [15:59<00:20,  2.43it/s]Saving model checkpoint to models/checkpoint-4000
Configuration saved in models/checkpoint-4000/config.json
Model weights saved in models/checkpoint-4000/pytorch_model.bin
tokenizer config file saved in models/checkpoint-4000/tokenizer_config.json
Special tokens file saved in models/checkpoint-4000/special_tokens_map.json
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4050/4050 [16:20<00:00,  4.61it/s]***** Running Evaluation *****
  Num examples = 60
  Batch size = 4
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4050/4050 [16:20<00:00,  4.61it/s]
Training completed. Do not forget to share your model on huggingface.co/models =)
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4050/4050 [16:20<00:00,  4.13it/s]