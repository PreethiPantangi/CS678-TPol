  0%|                                                                                                                              | 0/1125 [00:00<?, ?it/s]Traceback (most recent call last):
  File "roberta_translator.py", line 130, in <module>
    run(args)
  File "roberta_translator.py", line 101, in run
    trainer.train()
  File "/home/spantang/.local/lib/python3.8/site-packages/transformers/trainer.py", line 1349, in train
    for step, inputs in enumerate(epoch_iterator):
  File "/home/spantang/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 517, in __next__
    data = self._next_data()
  File "/home/spantang/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 557, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/spantang/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 47, in fetch
    return self.collate_fn(data)
  File "roberta_translator.py", line 37, in roberta_classifier_data_collator
    processed_data = tokenizer(input_texts, return_offsets_mapping=True, is_split_into_words=True, padding=True, return_tensors='pt')
  File "/home/spantang/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 2463, in __call__
    return self.batch_encode_plus(
  File "/home/spantang/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 2654, in batch_encode_plus
    return self._batch_encode_plus(
  File "/home/spantang/.local/lib/python3.8/site-packages/transformers/models/roberta/tokenization_roberta_fast.py", line 249, in _batch_encode_plus
    assert self.add_prefix_space or not is_split_into_words, (
AssertionError: You need to instantiate RobertaTokenizerFast with add_prefix_space=True to use it with pretokenized inputs.